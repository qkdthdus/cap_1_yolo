from ultralytics import YOLO
import cv2
import numpy as np
import time # ë¹„ë””ì˜¤ ì¬ìƒ ì†ë„ ì¡°ì ˆì„ ìœ„í•´ time ëª¨ë“ˆ ì¶”ê°€

# --------------------------
# ì„¤ì • ê°’
# --------------------------
VIDEO_FILES = [
    "./brand_pic/video1.mp4", 
    "./brand_pic/video2.mp4", 
    "./brand_pic/video3.mp4", 
    "./brand_pic/video4.mp4" 
]
TRIGGER_BOX_SIZE = 300
DEBUG_WINDOW_NAME = "Webcam Debug View (ESC to Quit)"
# ì°½ ë°°ì¹˜ ì„¤ì •
WINDOW_W, WINDOW_H = 320, 180 
START_X, START_Y = 50, 50
FULLSCREEN_TOGGLE_KEY = ord('q') 

# --------------------------
# YOLO ëª¨ë¸ ë¡œë“œ
# --------------------------
# YOLO ì‚¬ëŒ ëª¨ë¸ (ë°”ìš´ë”© ë°•ìŠ¤)
model = YOLO("yolov8n.pt") 

# YOLOv8 Pose ëª¨ë¸ ë¡œë“œ (ì† í¬ì¦ˆ ì¶”ì •ì„ ìœ„í•´)
try:
    # pose_model ë¡œë“œ ì‹œë„. ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ì²˜ë¦¬
    pose_model = YOLO("yolov8n-pose.pt")
except Exception as e:
    print("--- âš ï¸ ê²½ê³ : yolov8n-pose.pt ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ âš ï¸ ---")
    print(f"ì˜¤ë¥˜: {e}")
    print("YOLO Pose ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ê²½ë¡œì— ë‘ì‹­ì‹œì˜¤.")
    pose_model = None 

# --------------------------
# í—¬í¼ í•¨ìˆ˜
# --------------------------

# ì‚¬ëŒ ê°ì§€ (YOLO) - ê¸°ì¡´ ìœ ì§€
def detect_person(frame):
    close = False
    boxes = []
    # 0: person í´ë˜ìŠ¤
    results = model(frame, classes=0, verbose=False) 
    for r in results:
        for det in r.boxes:
            x1, y1, x2, y2 = map(int, det.xyxy[0].tolist())
            boxes.append((x1, y1, x2, y2))
            w = x2 - x1
            h = y2 - y1
            # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ ê°€ê¹Œìš´ ê²ƒìœ¼ë¡œ ê°„ì£¼
            if w >= TRIGGER_BOX_SIZE or h >= TRIGGER_BOX_SIZE: 
                close = True
    return close, boxes

# ğŸŒŸ ìˆ˜ì •ëœ ì† ìƒíƒœ ê°ì§€ í•¨ìˆ˜ (ì£¼ë¨¹/í¼ì¹¨ ì¶”ë¡ )
def get_hand_status_pose(frame):
    """
    YOLOv8 Pose ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì†ëª©ê³¼ íŒ”ê¿ˆì¹˜ ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 
    ì†ì´ í´ì§„ ìƒíƒœ(Open) ë˜ëŠ” ì£¼ë¨¹ ìƒíƒœ(Closed)ì¸ì§€ ì¶”ë¡ í•©ë‹ˆë‹¤.
    """
    if pose_model is None:
        return False, False # (ì£¼ë¨¹ ìƒíƒœ: False, í´ì§ ìƒíƒœ: False)

    # Pose ê°ì§€ ì‹¤í–‰
    pose_results = pose_model(frame, verbose=False)
    
    # í‚¤í¬ì¸íŠ¸ ì¸ë±ìŠ¤: 7: íŒ”ê¿ˆì¹˜(ì™¼), 8: íŒ”ê¿ˆì¹˜(ì˜¤), 9: ì†ëª©(ì™¼), 10: ì†ëª©(ì˜¤)
    WRIST_KPTS = [9, 10]
    ELBOW_KPTS = [7, 8]
    CONF_THRESHOLD = 0.5 
    # ì† ìƒíƒœ íŒë‹¨ ì„ê³„ê°’ (ì´ í”½ì…€ ê±°ë¦¬ë³´ë‹¤ ë©€ë©´ 'Open'ìœ¼ë¡œ ê°„ì£¼)
    MIN_DISTANCE = 50 

    hand_is_open = False
    hand_is_closed = False

    for r in pose_results:
        if r.keypoints is None or r.keypoints.data.numel() == 0:
            continue
            
        kpts = r.keypoints.data[0].cpu().numpy() 
        if kpts.shape[0] < 17: continue
        
        # 1. ê°ì§€ëœ í¬ì¦ˆê°€ í”„ë ˆì„ ì¤‘ì•™ ê·¼ì²˜ì— ìˆëŠ” ì‚¬ëŒì¸ì§€ í™•ì¸
        h, w = frame.shape[:2]
        x1, y1, x2, y2 = map(int, r.boxes.xyxy[0].tolist())
        person_center_x = (x1 + x2) // 2
        cam_center_x = w // 2
        if abs(person_center_x - cam_center_x) > w * 0.4: continue

        # 2. ì–‘ìª½ íŒ”/ì† ìƒíƒœ ë¶„ì„
        for wrist_idx, elbow_idx in zip(WRIST_KPTS, ELBOW_KPTS):
            wrist_kpt = kpts[wrist_idx]
            elbow_kpt = kpts[elbow_idx]
            
            # ë‘ í‚¤í¬ì¸íŠ¸ ëª¨ë‘ ì‹ ë¢°ë„ ì„ê³„ê°’ ì´ìƒì´ì–´ì•¼ í•¨
            if wrist_kpt[2] > CONF_THRESHOLD and elbow_kpt[2] > CONF_THRESHOLD:
                
                # ê±°ë¦¬ ê³„ì‚°
                wrist_pos = np.array([wrist_kpt[0], wrist_kpt[1]])
                elbow_pos = np.array([elbow_kpt[0], elbow_kpt[1]])
                distance = np.linalg.norm(wrist_pos - elbow_pos)
                
                # ì† í´ì§ ì¶”ë¡ : ê±°ë¦¬ê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ 'Open'ìœ¼ë¡œ ê°„ì£¼
                if distance > MIN_DISTANCE:
                    hand_is_open = True
                    # ë””ë²„ê¹…ìš©: í´ì§„ ì†ì— ë…¹ìƒ‰ ì›
                    cv2.circle(frame, (int(wrist_kpt[0]), int(wrist_kpt[1])), 8, (0, 255, 0), -1) 
                else:
                    # ê±°ë¦¬ê°€ ì„ê³„ê°’ ì´í•˜ë©´ 'Closed'ë¡œ ê°„ì£¼ (ì£¼ë¨¹ ë˜ëŠ” ì›…í¬ë¦° ìƒíƒœ)
                    hand_is_closed = True
                    # ë””ë²„ê¹…ìš©: ì£¼ë¨¹/ì›…í¬ë¦° ì†ì— ë¹¨ê°„ìƒ‰ ì›
                    cv2.circle(frame, (int(wrist_kpt[0]), int(wrist_kpt[1])), 8, (0, 0, 255), -1)

    return hand_is_closed, hand_is_open

# --------------------------
# 1ï¸âƒ£ OpenCV ì°½ ìƒì„± ë° ì´ˆê¸°í™” (ì°½ ê´€ë¦¬ ë¡œì§ ìœ ì§€)
# --------------------------
screen_units = []
is_fullscreen_mode = False

def toggle_fullscreen(unit_index):
    """ ì§€ì •ëœ ì°½ì„ ì „ì²´ í™”ë©´ ëª¨ë“œë¡œ í† ê¸€í•˜ê³  ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. """
    global screen_units, is_fullscreen_mode
    unit = screen_units[unit_index]

    is_fullscreen_mode = not is_fullscreen_mode 
    
    if is_fullscreen_mode:
        cv2.setWindowProperty(unit["win_name"], cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
    else:
        cv2.setWindowProperty(unit["win_name"], cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)
        # ì°½ ëª¨ë“œë¡œ ë³µê·€ ì‹œ ìœ„ì¹˜ì™€ í¬ê¸° ì¬ì§€ì •
        cv2.resizeWindow(unit["win_name"], WINDOW_W, WINDOW_H)
        
        row = unit_index // 2
        col = unit_index % 2
        pos_x = START_X + col * (WINDOW_W + 20)
        pos_y = START_Y + row * (WINDOW_H + 40)
        cv2.moveWindow(unit["win_name"], pos_x, pos_y)


for i in range(4): # 4ê°œì˜ ë¹„ë””ì˜¤ ì°½ ìƒì„±
    window_name = f"Video Monitor {i+1}"
    
    # ì°½ ë°°ì¹˜
    row = i // 2
    col = i % 2
    pos_x = START_X + col * (WINDOW_W + 20)
    pos_y = START_Y + row * (WINDOW_H + 40)
    
    # OpenCV ì°½ ìƒì„± ë° ìœ„ì¹˜ ì§€ì •
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, WINDOW_W, WINDOW_H)
    cv2.moveWindow(window_name, pos_x, pos_y)

    # ë¹„ë””ì˜¤ íŒŒì¼ì˜ ì²« í”„ë ˆì„ ë¡œë“œ
    cap_vid = cv2.VideoCapture(VIDEO_FILES[i])
    ret, first_frame = cap_vid.read()
    cap_vid.release()

    if not ret:
        raise Exception(f"ì˜ìƒ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {VIDEO_FILES[i]}")

    screen_units.append({
        "win_name": window_name,
        "active": False,
        "first_frame": first_frame,
        "video_path": VIDEO_FILES[i],
        "video_cap": None,
        "fps": 30,
        "index": i 
    })

# ì´ˆê¸° í™”ë©´ ì •ì§€ ìƒíƒœ í‘œì‹œ
for unit in screen_units:
    resized_frame = cv2.resize(unit["first_frame"], (WINDOW_W, WINDOW_H))
    cv2.imshow(unit["win_name"], resized_frame)

# ë””ë²„ê·¸ ì°½ ìƒì„± ë° ë°°ì¹˜
cv2.namedWindow(DEBUG_WINDOW_NAME, cv2.WINDOW_NORMAL)
cv2.moveWindow(DEBUG_WINDOW_NAME, START_X + 2 * (WINDOW_W + 20), START_Y)


# --------------------------
# 2ï¸âƒ£ ì›¹ìº  ë° ë©”ì¸ ë£¨í”„ (ìˆ˜ì •ëœ ë¡œì§ ì ìš©)
# --------------------------
cap = cv2.VideoCapture(0)
running = True

# ğŸŒŸ ì† ìƒíƒœ ì¶”ì  ë³€ìˆ˜: ì´ì „ í”„ë ˆì„ì—ì„œ ì†ì´ ì£¼ë¨¹ ìƒíƒœì˜€ëŠ”ì§€ ì¶”ì 
hand_was_closed = False 

while running:
    
    # 1. ì¹´ë©”ë¼ ì…ë ¥
    ret, frame = cap.read()
    if not ret: break
    
    # 2. ì‚¬ëŒ ê°ì§€ (YOLO)
    person_close, boxes = detect_person(frame)

    # 3. ì† í¬ì¦ˆ ê°ì§€ ë° ìƒíƒœ í™•ì¸ (ìˆ˜ì •ëœ í•¨ìˆ˜)
    # hand_is_closed: í˜„ì¬ í”„ë ˆì„ì—ì„œ ì£¼ë¨¹ ìƒíƒœì¸ê°€?
    # hand_is_open: í˜„ì¬ í”„ë ˆì„ì—ì„œ í´ì§ ìƒíƒœì¸ê°€?
    hand_is_closed, hand_is_open = get_hand_status_pose(frame) 
    
    # ğŸŒŸ ìµœì¢… íŠ¸ë¦¬ê±° ì¡°ê±´ (ì£¼ë¨¹->í•„ ë•Œ)
    # 1. ì‚¬ëŒì´ ê°€ê¹Œì´ ìˆê³  (person_close)
    # 2. í˜„ì¬ ì†ì´ í´ì§„ ìƒíƒœì´ë©° (hand_is_open)
    # 3. ì§ì „ í”„ë ˆì„ì—ì„œëŠ” ì£¼ë¨¹ ìƒíƒœì˜€ì„ ë•Œ (hand_was_closed)
    trigger = person_close and hand_is_open and hand_was_closed

    # 4. ë‹¤ìŒ í”„ë ˆì„ì„ ìœ„í•œ ìƒíƒœ ì—…ë°ì´íŠ¸
    # í˜„ì¬ì˜ 'ì£¼ë¨¹ ìƒíƒœ'ë¥¼ ë‹¤ìŒ ë£¨í”„ì˜ 'ì´ì „ ì£¼ë¨¹ ìƒíƒœ'ë¡œ ì €ì¥
    hand_was_closed = hand_is_closed
    
    # 5. ëª¨ë‹ˆí„° ê°œë³„ ì²˜ë¦¬ (íŠ¸ë¦¬ê±° ë¡œì§ ì ìš©)
    for unit in screen_units:

        # A) íŠ¸ë¦¬ê±° ë°œìƒ â†’ ë¹„ë””ì˜¤ ì‹œì‘
        if trigger and not unit["active"]:
            unit["active"] = True
            unit["video_cap"] = cv2.VideoCapture(unit["video_path"])
            unit["fps"] = unit["video_cap"].get(cv2.CAP_PROP_FPS) or 30 
            unit["delay_ms"] = int(1000 / unit["fps"])
            unit["start_time"] = time.time() # ë¹„ë””ì˜¤ ì¬ìƒ ì‹œê°„ ê¸°ë¡

        # B) ì¬ìƒ ì¤‘ì´ë©´ í”„ë ˆì„ ì½ê¸°
        if unit["active"]:
            # FPSì— ë§ì¶° ë”œë ˆì´ ê³„ì‚°
            elapsed_time = time.time() - unit["start_time"]
            # frame_delay = elapsed_time * unit["fps"]
            
            ret_vid, vid_frame = unit["video_cap"].read()

            if ret_vid:
                # ì „ì²´ í™”ë©´ì´ ì•„ë‹ ë•Œë§Œ ë¦¬ì‚¬ì´ì§•
                if not is_fullscreen_mode:
                    vid_frame = cv2.resize(vid_frame, (WINDOW_W, WINDOW_H))
                cv2.imshow(unit["win_name"], vid_frame)
            else:
                # ì˜ìƒ ë â†’ ì •ì§€ í™”ë©´ ë³µê·€
                unit["active"] = False
                if unit["video_cap"]:
                    unit["video_cap"].release()
                
                resized_frame = cv2.resize(unit["first_frame"], (WINDOW_W, WINDOW_H))
                cv2.imshow(unit["win_name"], resized_frame)

        # C) ì¬ìƒ ì¤‘ ì•„ë‹ˆë©´ ì²« í™”ë©´ ìœ ì§€
        elif not unit["active"]:
            pass 

    
    # 6. ë””ë²„ê¹… í™”ë©´ ë° í‚¤ ì…ë ¥ ì²˜ë¦¬
    dbg = frame.copy()
    h_cam, w_cam = dbg.shape[:2]
    
    # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
    if trigger:
        cv2.putText(dbg, "TRIGGER: ì£¼ë¨¹ -> í¼ì¹¨! (ON)", (10, h_cam - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)
    else:
        status_text = f"CLOSE: {person_close} / CLOSED: {hand_is_closed} / OPEN: {hand_is_open} / WAS_CLOSED: {hand_was_closed}"
        cv2.putText(dbg, f"TRIGGER: OFF ({status_text})", (10, h_cam - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)
    
    # ë””ë²„ê·¸ ì°½ì— ì‚¬ëŒ ê°ì§€ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    for x1, y1, x2, y2 in boxes: 
        cv2.rectangle(dbg, (x1, y1), (x2, y2), (255, 255, 0), 2)
        
    cv2.imshow(DEBUG_WINDOW_NAME, cv2.resize(dbg, (dbg.shape[1]//2, dbg.shape[0]//2)))
    
    # í‚¤ ì…ë ¥ ê°ì§€
    key = cv2.waitKey(1)
    
    if key & 0xFF == 27: # ESC ì¢…ë£Œ
        running = False
    elif key == FULLSCREEN_TOGGLE_KEY: # 'q' í‚¤ ì…ë ¥ ì‹œ
        toggle_fullscreen(0) # 0ë²ˆ ëª¨ë‹ˆí„°ë§Œ ì „ì²´ í™”ë©´ í† ê¸€
    
    # ë””ë²„ê·¸ ì°½ì´ ë‹«íˆë©´ ì¢…ë£Œ
    if cv2.getWindowProperty(DEBUG_WINDOW_NAME, cv2.WND_PROP_VISIBLE) < 1:
        running = False


# --------------------------
# ì¢…ë£Œ
# --------------------------
cap.release()
cv2.destroyAllWindows()
